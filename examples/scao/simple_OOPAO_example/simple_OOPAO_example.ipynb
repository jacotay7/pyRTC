{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================\n",
      "     °          *      *      \n",
      " ▄██▄   ▄██▄  ▄███▄   ▄██▄ * ▄██▄ \n",
      "██* ██ ██  ██ ██  ██ ██  ██ ██  ██\n",
      "██  ██ ██° ██ ██  ██ ██* ██ ██  ██\n",
      "██  ██ ██  ██ ████▀  ██▄▄██ ██  ██\n",
      "██* ██ ██  ██ ██     ██▀▀██ ██  ██\n",
      "██  ██ ██  ██ ██ *   ██  ██ ██* ██\n",
      " ▀██▀   ▀██▀  ██   ° ██  ██  ▀██▀ \n",
      "      *         *             \n",
      "==================================\n",
      "\n",
      "\n",
      "**************************************************************************************************************************************************************\n",
      "NUMPY WARNING: mkl blas not found! Multi-threading may not work as expected.\n",
      "**************************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import hardware classes\n",
    "from pyRTC.hardware.OOPAOInterface import OOPAOInterface\n",
    "from pyRTC.SlopesProcess import SlopesProcess\n",
    "from pyRTC.Pipeline import *\n",
    "from pyRTC.Loop import Loop\n",
    "# from pyRTC.hardware.LoopGymInterface import LoopGymInterface\n",
    "\n",
    "import gymnasium\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nShared memory in python is a bit annoying, we are required to unlink it from the garbage collector\\nso that it will stick around in between runs, however sometime you can get into a situation where \\nthe SHM is not intialized properly. Usually you will see an error like: \\nTypeError: buffer is too small for requested array\\n\\nTo reset a SHM you can run the following code. Note: it will throw some garbage collector errors.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Shared memory in python is a bit annoying, we are required to unlink it from the garbage collector\n",
    "so that it will stick around in between runs, however sometime you can get into a situation where \n",
    "the SHM is not intialized properly. Usually you will see an error like: \n",
    "TypeError: buffer is too small for requested array\n",
    "\n",
    "To reset a SHM you can run the following code. Note: it will throw some garbage collector errors.\n",
    "\"\"\"\n",
    "# shm_names = [\"wfs\", \"wfsRaw\", \"wfc\", \"wfc2D\", \"signal\", \"signal2D\", \"psfShort\", \"psfLong\"] #list of SHMs to reset\n",
    "# clear_shms(shm_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gain': 0.1, 'numDroppedModes': 0, 'pokeAmp': 1e-06, 'numItersIM': 10, 'affinity': 2, 'method': 'push-pull', 'IMFile': 'simpleIM.npy', 'functions': ['standardIntegrator']}\n",
      "{'name': 'OOPAOWFS', 'width': 32, 'height': 32, 'darkCount': 10, 'affinity': 3, 'functions': ['expose']}\n",
      "{'name': 'OOPAOWFC', 'numActuators': 21, 'numModes': 18, 'flatFile': '', 'saveFile': 'flat.npy', 'm2cFile': '', 'affinity': 3, 'commandCap': 0.8, 'hardwareDelay': 0.1, 'frameDelay': 0, 'functions': ['sendToHardware']}\n",
      "{'name': 'OOPAOPSF', 'index': 0, 'width': 160, 'height': 160, 'darkCount': 1000, 'integration': 100, 'affinity': 3, 'functions': ['expose']}\n",
      "{'type': 'SHWFS', 'signalType': 'slopes', 'affinity': 4, 'refSlopesFile': '', 'validSubApsFile': '', 'subApSpacing': 8, 'subApOffsetX': 0, 'subApOffsetY': 0, 'functions': ['computeSignal']}\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration file\n",
    "def read_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        conf = yaml.safe_load(file)\n",
    "    return conf\n",
    "\n",
    "#Now we can read our YAML config file \n",
    "conf = read_yaml_file(\"simple_OOPAO_config.yaml\")\n",
    "\n",
    "#And separate it into sections for each of our AO loop components\n",
    "confLoop = conf[\"loop\"]\n",
    "confWFS = conf[\"wfs\"]\n",
    "confWFC = conf[\"wfc\"]\n",
    "confPSF = conf[\"psf\"]\n",
    "confSlopes = conf[\"slopes\"]\n",
    "\n",
    "print(confLoop)\n",
    "print(confWFS)\n",
    "print(confWFC)\n",
    "print(confPSF)\n",
    "print(confSlopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading/Writting calibration data from data_calibration/\n",
      "Writting output data in data_cl/\n"
     ]
    }
   ],
   "source": [
    "from simpleParamFile import *\n",
    "param = initializeParameterFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% TELESCOPE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "     Diameter             1                [m]        \n",
      "    Resolution            32             [pixels]     \n",
      "    Pixel Size           0.03              [m]        \n",
      "     Surface             1.0               [m2]       \n",
      "Central Obstruction       0.0         [% of diameter]  \n",
      "Pixels in the pupil       812             [pixels]     \n",
      "      Source             None                         \n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "No light propagated through the telescope\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% TELESCOPE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "     Diameter             1                [m]        \n",
      "    Resolution            32             [pixels]     \n",
      "    Pixel Size           0.03              [m]        \n",
      "     Surface             1.0               [m2]       \n",
      "Central Obstruction       0.0         [% of diameter]  \n",
      "Pixels in the pupil       812             [pixels]     \n",
      "      Source             None                         \n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "No light propagated through the telescope\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SOURCE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      " Source Wavelength Zenith  Azimuth   Altitude Magnitude    Flux   \n",
      "           [m]    [arcsec]  [deg]      [m]              [phot/m2/s]\n",
      "-------------------------------------------------------------------\n",
      "  NGS   2.179e-06    0        0        inf       4.0    47780448.4\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SOURCE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      " Source Wavelength Zenith  Azimuth   Altitude Magnitude    Flux   \n",
      "           [m]    [arcsec]  [deg]      [m]              [phot/m2/s]\n",
      "-------------------------------------------------------------------\n",
      "  NGS    6.4e-07     0        0        inf       4.0    273031133.9\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "No coordinates loaded.. taking the cartesian geometry as a default\n",
      "Generating a Deformable Mirror: \n",
      "Computing the 2D zonal modes...\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DEFORMABLE MIRROR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Controlled Actuators         21        \n",
      "         M4                False       \n",
      "        Pitch               0.25              [m]        \n",
      " Mechanical Coupling        0.45              [%]        \n",
      "-------------------------------------------------------------------------------\n",
      "Mis-registration:\n",
      "Rotation [deg]\tShift X [m]\tShift Y [m]\tRadial Scaling [%]\tTangential Scaling [%]\n",
      "      0       \t     0     \t     0     \t        0         \t          0           \n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Selecting valid subapertures based on flux considerations..\n",
      "Acquiring reference slopes..\n",
      "Done!\n",
      "Setting slopes units..\n",
      "Done!\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SHACK HARTMANN WFS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "    Subapertures            4         \n",
      "  Subaperture Size         0.25              [m]        \n",
      "     Pixel FoV             0.26            [arcsec]     \n",
      "   Subapertue FoV          2.11            [arcsec]     \n",
      " Valid Subaperture          12        \n",
      "   Binning Factor           1         \n",
      "   Geometric WFS          False       \n",
      "  Shannon Sampling         True       \n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Creation of layer1/1 ...\n",
      "-> Computing the initial phase screen...\n",
      "initial phase screen : 0.0016047954559326172 s\n",
      "ZZt.. : 0.041455745697021484 s\n",
      "ZXt.. : 0.02512502670288086 s\n",
      "XXt.. : 0.01854109764099121 s\n",
      "Done!\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ATMOSPHERE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "   Layer     Direction     Speed      Altitude      Cn2     \n",
      "               [deg]       [m/s]        [m]       [m-2/3]   \n",
      "----------------------------------------------------------------------\n",
      "     1           0           10          0           1      \n",
      "------------------------------------------------------------------\n",
      "    r0 @500 nm         0.1 [m]      \n",
      "        L0              30 [m]      \n",
      "  Seeing @500nm        1.03 [\"]     \n",
      "    Frequency        1000.0 [Hz]    \n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Opening Existing Shared Memory Object wfsRaw\n",
      "Opening Existing Shared Memory Object wfsRaw_meta\n",
      "Opening Existing Shared Memory Object wfs\n",
      "Opening Existing Shared Memory Object wfs_meta\n",
      "Opening Existing Shared Memory Object wfc\n",
      "Opening Existing Shared Memory Object wfc_meta\n",
      "Closing wfc\n",
      "Opening Existing Shared Memory Object wfc\n",
      "Opening Existing Shared Memory Object wfc_meta\n",
      "Opening Existing Shared Memory Object wfc2D\n",
      "Opening Existing Shared Memory Object wfc2D_meta\n",
      "Opening Existing Shared Memory Object psfShort\n",
      "Opening Existing Shared Memory Object psfShort_meta\n",
      "Opening Existing Shared Memory Object psfLong\n",
      "Opening Existing Shared Memory Object psfLong_meta\n",
      "Telescope and Atmosphere combined!\n",
      "Telescope and Atmosphere combined!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM VALID ACT: 21\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create the OOPAO simulation interface object \n",
    "Running this cell will initialize the dm, wfs, psf, and slopes objects, \n",
    "but will not start their real time computations. This inialization includes\n",
    "the creation of the Shared Memory Objects, and the simulation inialization.\n",
    "\"\"\"\n",
    "sim = OOPAOInterface(conf=conf, param=param)\n",
    "wfs, dm, psf = sim.get_hardware()\n",
    "\n",
    "plt.imshow(wfs.wfs.cam.frame)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(dm.layout)\n",
    "plt.show()\n",
    "\n",
    "print(f\"NUM VALID ACT: {np.sum(dm.layout)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME ELAPSED: 0 sec. COMPLETED: 100 %\n",
      "NMAX =  17\n",
      "RMS opd error = [[1.69814834e-08 6.46646817e-08 6.46646817e-08]]\n",
      "RMS Positions = [[1.75602688e-07 5.60200196e-07 5.60200196e-07]]\n",
      "MAX Positions = [[6.19665037e-07 9.99272119e-07 9.99272119e-07]]\n",
      "WARNING: Number of modes requested too high, taking the maximum value possible!\n",
      "KL WITH DOUBLE DIAGONALISATION: COVARIANCE ERROR =  3.58125053213961e-14\n",
      "Closing wfc\n",
      "Opening Existing Shared Memory Object wfc\n",
      "Opening Existing Shared Memory Object wfc_meta\n",
      "Opening Existing Shared Memory Object wfs_meta\n",
      "Closing wfs_meta\n",
      "Opening Existing Shared Memory Object wfs\n",
      "Opening Existing Shared Memory Object wfs_meta\n",
      "subApSpacing: 8\n",
      "numRegions: 4\n",
      "offsetX: 0\n",
      "offsetY: 0\n",
      "signalSize: 32\n",
      "signalShape: (32,)\n",
      "signalDType: <class 'numpy.float32'>\n",
      "Opening Existing Shared Memory Object signal\n",
      "Opening Existing Shared Memory Object signal_meta\n",
      "Opening Existing Shared Memory Object signal2D\n",
      "Opening Existing Shared Memory Object signal2D_meta\n",
      "Opening Existing Shared Memory Object signal_meta\n",
      "Closing signal_meta\n",
      "Opening Existing Shared Memory Object signal\n",
      "Opening Existing Shared Memory Object signal_meta\n",
      "Opening Existing Shared Memory Object signal2D_meta\n",
      "Closing signal2D_meta\n",
      "Opening Existing Shared Memory Object signal2D\n",
      "Opening Existing Shared Memory Object signal2D_meta\n",
      "Opening Existing Shared Memory Object wfc_meta\n",
      "Closing wfc_meta\n",
      "Opening Existing Shared Memory Object wfc\n",
      "Opening Existing Shared Memory Object wfc_meta\n",
      "Opening Existing Shared Memory Object wfc2D_meta\n",
      "Closing wfc2D_meta\n",
      "Opening Existing Shared Memory Object wfc2D\n",
      "Opening Existing Shared Memory Object wfc2D_meta\n",
      "Registering Work Function standardIntegrator on CPU 2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "It's important to set the full basis and number of possible modes before\n",
    "initializing the loop object. Here I define a KL basis for the system\n",
    "\"\"\"\n",
    "from OOPAO.calibration.compute_KL_modal_basis import compute_KL_basis\n",
    "\n",
    "NUM_MODES = 18\n",
    "\n",
    "M2C_KL = compute_KL_basis(sim.tel, sim.atm, sim.dm)\n",
    "dm.setM2C(M2C_KL[:,:NUM_MODES])\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "slopes = SlopesProcess(conf=conf)\n",
    "\n",
    "\"\"\" \n",
    "\"\"\"\n",
    "#Initialize our AO loop object\n",
    "loop = Loop(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 21)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Start the processes. Here the real-time computations selected in\n",
    "the config will begin.\n",
    "\"\"\"\n",
    "dm.start()\n",
    "dm.flatten()\n",
    "\n",
    "wfs.start()\n",
    "slopes.start()\n",
    "\n",
    "#Take new reference slopes while dm is flat.\n",
    "# time.sleep(1)\n",
    "# slopes.takeRefSlopes()\n",
    "\n",
    "print(sim.dm.OPD.shape)\n",
    "psf.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telescope and Atmosphere combined!\n",
      "Telescope and Atmosphere combined!\n"
     ]
    }
   ],
   "source": [
    "sim.addAtmosphere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 30}\n",
    "\n",
    "    def __init__(self, loop, render_mode=None, buffer=0):\n",
    "        super().__init__()\n",
    "        self.loop = loop\n",
    "        self.buffer = buffer\n",
    "        self.render_mode = render_mode\n",
    "        self.default_action = np.zeros(self.loop.confWFC['numModes'], dtype=np.float32)\n",
    "        self.flat2D = self.flat2D = np.zeros((self.loop.wfc2D_width, self.loop.wfc2D_height))\n",
    "        self.active_modes = self.loop.numActiveModes\n",
    "    \n",
    "        self.slope_norm = 10\n",
    "        self.cmd_norm = 1e-7\n",
    "        self.timestep_limit = 1e10\n",
    "        self.current_step = 0\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        \n",
    "        # Example for using image as input (channel-first; channel-last also works):\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                \"slopes\": spaces.Box(low=-1, high=1,\n",
    "                                            shape=(self.loop.slopes_width, self.loop.slopes_height), dtype=np.float32),\n",
    "                \"command\": spaces.Box(low=-1, high=1,\n",
    "                                            shape=(self.loop.wfc2D_width, self.loop.wfc2D_height), dtype=np.float32)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.loop.confWFC[\"numModes\"], ) , dtype=np.float32)\n",
    "\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"A private method to build an observation from a state\"\"\"\n",
    "\n",
    "\n",
    "        self._normalized_cmd2D = self._cmd2D_obs / self.cmd_norm\n",
    "\n",
    "        self._normalized_slopes = self._slopes_obs / self.slope_norm\n",
    "\n",
    "        return {\"slopes\": self._normalized_slopes, \"command\": self._normalized_cmd2D}\n",
    "    \n",
    "    \n",
    "    def _get_info(self):\n",
    "        return {\n",
    "            'TimeLimit.truncated': False\n",
    "        }\n",
    "    \n",
    "\n",
    "    def _send_control(self, control):\n",
    "\n",
    "        control[self.active_modes:] = 0\n",
    "\n",
    "        self.control = control * self.cmd_norm\n",
    "        \n",
    "        self.loop.wfcShm.write(self.control)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "\n",
    "        #send the command to the mirror\n",
    "        self._send_control(action)\n",
    "\n",
    "        # make a blocking read of the wfc to make sure the action has been set\n",
    "        self._cmd2D_obs = self.loop.wfc2DShm.read()\n",
    "\n",
    "        # read the slopes\n",
    "        self._slopes_obs = self.loop.slopesShm.read()\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        # Compute reward\n",
    "        reward = np.exp(-np.var(self._slopes_obs), dtype=np.float32).item()\n",
    "\n",
    "        #Terminated condition -> divergent slopes\n",
    "        terminated = bool(reward < np.exp(-9))\n",
    "\n",
    "        # Info + Truncation\n",
    "        if self.current_step >= self.timestep_limit:\n",
    "            truncated = True\n",
    "            info = {'TimeLimit.truncated': True}\n",
    "        else:\n",
    "            truncated = False\n",
    "            info = {'TimeLimit.truncated': False}\n",
    "\n",
    "        \n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.current_step = 0\n",
    "\n",
    "        #Flatten the mirror\n",
    "        self._send_control(self.default_action)\n",
    "\n",
    "        # Sleep to make sure the blocking order is reset\n",
    "        time.sleep(0.01)\n",
    "\n",
    "        #Set the current command\n",
    "        self._cmd2D_obs = self.loop.wfc2DShm.read()\n",
    "\n",
    "        #Read the slopes\n",
    "        self._slopes_obs = self.loop.slopesShm.read()\n",
    "\n",
    "        #Build the observation\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        # Get info dict\n",
    "        info = self._get_info()\n",
    "\n",
    "    \n",
    "        return observation, info\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == None:\n",
    "            return\n",
    "\n",
    "    def close(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyRTC.hardware.GymEnv import CustomEnv\n",
    "\n",
    "env = CustomEnv(loop=loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "for i in range(1000):\n",
    "    obs, reward, *_ = env.step(env.action_space.sample())\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "obs, *_ = env.step(env.action_space.sample())\n",
    "\n",
    "plt.imshow(obs['slopes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common import env_checker\n",
    "\n",
    "env_checker.check_env(env, warn=True, skip_render_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch as th\n",
    "from torch import nn\n",
    "\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "\n",
    "class CustomCombinedExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Dict):\n",
    "        # We do not know features-dim here before going over all the items,\n",
    "        # so put something dummy for now. PyTorch requires calling\n",
    "        # nn.Module.__init__ before adding modules\n",
    "        super().__init__(observation_space, features_dim=1)\n",
    "\n",
    "        self._numFeatures = 32\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding='same'),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='valid'),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Flatten())\n",
    "        \n",
    "\n",
    "        # find the output size of the CNN for each obs\n",
    "        n_flatten = {}\n",
    "\n",
    "        with th.no_grad():\n",
    "            for key, subspace in observation_space.spaces.items():\n",
    "                # print(observation_space.sample()[key].shape)\n",
    "                n_flatten[key] = self.cnn(\n",
    "                    th.as_tensor(observation_space.sample()[key][np.newaxis,np.newaxis,:,:]).float()\n",
    "                ).shape[1]\n",
    "\n",
    "        \n",
    "        # with th.no_grad():\n",
    "        #     for key, subspace in observation_space.spaces.items():\n",
    "\n",
    "        #         sample = observation_space.sample()[key][np.newaxis,np.newaxis,:,:]\n",
    "\n",
    "        #         n_flatten[key] = self._get_conv_output(sample.shape)\n",
    "\n",
    "        \n",
    "\n",
    "               \n",
    "\n",
    "        # print(n_flatten)        \n",
    "\n",
    "    \n",
    "        extractors = {}\n",
    "\n",
    "        # We need to know size of the output of this extractor,\n",
    "        # so go over all the spaces and compute output feature sizes\n",
    "        for key, subspace in observation_space.spaces.items():\n",
    "            if key == \"slopes\":\n",
    "                # We will just downsample one channel of the image by 4x4 and flatten.\n",
    "                # Assume the image is single-channel (subspace.shape[0] == 0)\n",
    "                extractors[key] = nn.Sequential(self.cnn,\n",
    "                                nn.Linear(n_flatten[key], self._numFeatures),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Flatten())\n",
    "                \n",
    "            elif key == \"command\":\n",
    "                # Run through a simple MLP\n",
    "                extractors[key] = nn.Sequential(self.cnn,\n",
    "                                nn.Linear(n_flatten[key], self._numFeatures),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Flatten())\n",
    "\n",
    "        self.extractors = nn.ModuleDict(extractors)\n",
    "\n",
    "        # Update the features dim manually\n",
    "        self._features_dim = 64\n",
    "\n",
    "    def forward(self, observations) -> th.Tensor:\n",
    "        encoded_tensor_list = []\n",
    "\n",
    "        # self.extractors contain nn.Modules that do all the processing.\n",
    "        for key, extractor in self.extractors.items():\n",
    "            # print(th.Tensor(observations[key][:, np.newaxis, :, :]).shape)\n",
    "            # print(extractor(th.Tensor(observations[key][:, np.newaxis,:, :])).shape)\n",
    "            feature = extractor(th.Tensor(observations[key][:, np.newaxis, :, :]))\n",
    "\n",
    "            feature = feature.reshape(feature.shape[0], -1)\n",
    "\n",
    "            encoded_tensor_list.append(feature)\n",
    "        # Return a (B, self._features_dim) PyTorch tensor, where B is batch dimension.\n",
    "        return th.cat(encoded_tensor_list, dim=1)\n",
    "\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        # Helper function to calculate the size of the flattened features after conv layers\n",
    "            with th.no_grad():\n",
    "                input = th.rand(1, *shape)\n",
    "                output = self.cnn(input)\n",
    "                return int(th.prod(th.tensor(output.size()[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim: int,\n",
    "        last_layer_dim_pi: int = 64,\n",
    "        last_layer_dim_vf: int = 64,\n",
    "        hidden_size: int = 128,  # LSTM hidden layer size\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.latent_dim_pi = last_layer_dim_pi\n",
    "        self.latent_dim_vf = last_layer_dim_vf\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=feature_dim, hidden_size=hidden_size, batch_first=True)\n",
    "\n",
    "        # Policy network\n",
    "        self.policy_net = nn.Sequential(\n",
    "            nn.Linear(hidden_size, last_layer_dim_pi), nn.ReLU()\n",
    "        )\n",
    "        # Value network\n",
    "        self.value_net = nn.Sequential(\n",
    "            nn.Linear(hidden_size, last_layer_dim_vf), nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, features: th.Tensor, hx=None) -> Tuple[th.Tensor, th.Tensor, th.Tensor]:\n",
    "        features = features.unsqueeze(1)  # Add sequence dimension (batch, sequence, feature)\n",
    "        if hx is None:\n",
    "            lstm_out, hx = self.lstm(features)\n",
    "        else:\n",
    "            lstm_out, hx = self.lstm(features, hx)\n",
    "        lstm_out = lstm_out.squeeze(1)  # Remove the sequence dimension\n",
    "        return self.forward_actor(lstm_out), self.forward_critic(lstm_out), hx\n",
    "\n",
    "    def forward_actor(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.policy_net(features)\n",
    "\n",
    "    def forward_critic(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.value_net(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.type_aliases import PyTorchObs, Schedule\n",
    "from stable_baselines3.common.distributions import (\n",
    "    BernoulliDistribution,\n",
    "    CategoricalDistribution,\n",
    "    DiagGaussianDistribution,\n",
    "    Distribution,\n",
    "    MultiCategoricalDistribution,\n",
    "    StateDependentNoiseDistribution,\n",
    "    make_proba_distribution,\n",
    ")\n",
    "\n",
    "class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_space: spaces.Space,\n",
    "        action_space: spaces.Space,\n",
    "        lr_schedule: Callable[[float], float],\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        kwargs[\"ortho_init\"] = False  # Disable orthogonal initialization\n",
    "        super().__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.hidden_state = None\n",
    "\n",
    "    def _build_mlp_extractor(self) -> None:\n",
    "        self.mlp_extractor = CustomNetwork(self.features_dim)\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, obs: th.Tensor, deterministic: bool = False) -> Tuple[th.Tensor, th.Tensor, th.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass in all the networks (actor and critic)\n",
    "\n",
    "        :param obs: Observation\n",
    "        :param deterministic: Whether to sample or use deterministic actions\n",
    "        :return: action, value and log probability of the action\n",
    "        \"\"\"\n",
    "        # Preprocess the observation if needed\n",
    "        features = self.extract_features(obs)\n",
    "        hx_in = self.hidden_state\n",
    "        \n",
    "        if self.share_features_extractor:\n",
    "            latent_pi, latent_vf, hx_out = self.mlp_extractor(features, hx_in)\n",
    "            self.hidden_state = hx_out\n",
    "        else:\n",
    "            pi_features, vf_features = features\n",
    "            latent_pi = self.mlp_extractor.forward_actor(pi_features)\n",
    "            latent_vf = self.mlp_extractor.forward_critic(vf_features)\n",
    "        # Evaluate the values for the given observations\n",
    "        values = self.value_net(latent_vf)\n",
    "        distribution = self._get_action_dist_from_latent(latent_pi)\n",
    "        actions = distribution.get_actions(deterministic=deterministic)\n",
    "        log_prob = distribution.log_prob(actions)\n",
    "        actions = actions.reshape((-1, *self.action_space.shape))  # type: ignore[misc]\n",
    "        return actions, values, log_prob\n",
    "\n",
    "    def predict_values(self, obs: PyTorchObs) -> th.Tensor:\n",
    "        \"\"\"\n",
    "        Get the estimated values according to the current policy given the observations.\n",
    "\n",
    "        :param obs: Observation\n",
    "        :return: the estimated values.\n",
    "        \"\"\"\n",
    "        features = super().extract_features(obs, self.vf_features_extractor)\n",
    "        _, latent_vf, _ = self.mlp_extractor.forward(features, self.hidden_state)\n",
    "        return self.value_net(latent_vf)\n",
    "    \n",
    "    def evaluate_actions(self, obs: PyTorchObs, actions: th.Tensor) -> Tuple[th.Tensor, th.Tensor, Optional[th.Tensor]]:\n",
    "        \"\"\"\n",
    "        Evaluate actions according to the current policy,\n",
    "        given the observations.\n",
    "\n",
    "        :param obs: Observation\n",
    "        :param actions: Actions\n",
    "        :return: estimated value, log likelihood of taking those actions\n",
    "            and entropy of the action distribution.\n",
    "        \"\"\"\n",
    "        # Preprocess the observation if needed\n",
    "        features = self.extract_features(obs)\n",
    "        if self.share_features_extractor:\n",
    "            latent_pi, latent_vf, _ = self.mlp_extractor(features)\n",
    "        else:\n",
    "            pi_features, vf_features = features\n",
    "            latent_pi = self.mlp_extractor.forward_actor(pi_features)\n",
    "            latent_vf = self.mlp_extractor.forward_critic(vf_features)\n",
    "        distribution = self._get_action_dist_from_latent(latent_pi)\n",
    "        log_prob = distribution.log_prob(actions)\n",
    "        values = self.value_net(latent_vf)\n",
    "        entropy = distribution.entropy()\n",
    "        return values, log_prob, entropy\n",
    "\n",
    "    def get_distribution(self, obs: PyTorchObs) -> Distribution:\n",
    "        \"\"\"\n",
    "        Get the current policy distribution given the observations.\n",
    "\n",
    "        :param obs:\n",
    "        :return: the action distribution.\n",
    "        \"\"\"\n",
    "        features = super().extract_features(obs, self.pi_features_extractor)\n",
    "        latent_pi, *_ = self.mlp_extractor.forward(features)\n",
    "        return self._get_action_dist_from_latent(latent_pi)\n",
    "\n",
    "\n",
    "\n",
    "    def reset_lstm_state(self):\n",
    "        self.hidden_state = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.base_class import BaseAlgorithm\n",
    "from stable_baselines3.common.buffers import DictRolloutBuffer, RolloutBuffer\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.type_aliases import GymEnv, MaybeCallback, Schedule\n",
    "from stable_baselines3.common.utils import obs_as_tensor, safe_mean\n",
    "from stable_baselines3.common.vec_env import VecEnv\n",
    "\n",
    "class CustomPPO(PPO):\n",
    "\n",
    "    def collect_rollouts(\n",
    "            self,\n",
    "            env: VecEnv,\n",
    "            callback: BaseCallback,\n",
    "            rollout_buffer: RolloutBuffer,\n",
    "            n_rollout_steps: int,\n",
    "        ) -> bool:\n",
    "            \"\"\"\n",
    "            Collect experiences using the current policy and fill a ``RolloutBuffer``.\n",
    "            The term rollout here refers to the model-free notion and should not\n",
    "            be used with the concept of rollout used in model-based RL or planning.\n",
    "\n",
    "            :param env: The training environment\n",
    "            :param callback: Callback that will be called at each step\n",
    "                (and at the beginning and end of the rollout)\n",
    "            :param rollout_buffer: Buffer to fill with rollouts\n",
    "            :param n_rollout_steps: Number of experiences to collect per environment\n",
    "            :return: True if function returned with at least `n_rollout_steps`\n",
    "                collected, False if callback terminated rollout prematurely.\n",
    "            \"\"\"\n",
    "            assert self._last_obs is not None, \"No previous observation was provided\"\n",
    "            # Switch to eval mode (this affects batch norm / dropout)\n",
    "            self.policy.set_training_mode(False)\n",
    "\n",
    "            n_steps = 0\n",
    "            rollout_buffer.reset()\n",
    "            # Sample new weights for the state dependent exploration\n",
    "            if self.use_sde:\n",
    "                self.policy.reset_noise(env.num_envs)\n",
    "\n",
    "            callback.on_rollout_start()\n",
    "\n",
    "            while n_steps < n_rollout_steps:\n",
    "                if self.use_sde and self.sde_sample_freq > 0 and n_steps % self.sde_sample_freq == 0:\n",
    "                    # Sample a new noise matrix\n",
    "                    self.policy.reset_noise(env.num_envs)\n",
    "\n",
    "                with th.no_grad():\n",
    "                    # Convert to pytorch tensor or to TensorDict\n",
    "                    obs_tensor = obs_as_tensor(self._last_obs, self.device)\n",
    "                    actions, values, log_probs = self.policy(obs_tensor)\n",
    "                actions = actions.cpu().numpy()\n",
    "\n",
    "                # Rescale and perform action\n",
    "                clipped_actions = actions\n",
    "\n",
    "                if isinstance(self.action_space, spaces.Box):\n",
    "                    if self.policy.squash_output:\n",
    "                        # Unscale the actions to match env bounds\n",
    "                        # if they were previously squashed (scaled in [-1, 1])\n",
    "                        clipped_actions = self.policy.unscale_action(clipped_actions)\n",
    "                    else:\n",
    "                        # Otherwise, clip the actions to avoid out of bound error\n",
    "                        # as we are sampling from an unbounded Gaussian distribution\n",
    "                        clipped_actions = np.clip(actions, self.action_space.low, self.action_space.high)\n",
    "\n",
    "                new_obs, rewards, dones, infos = env.step(clipped_actions)\n",
    "\n",
    "                \n",
    "                if dones:\n",
    "                    print('#############')\n",
    "                    print(dones)\n",
    "                    print('############')\n",
    "                    self.policy.reset_lstm_state()\n",
    "\n",
    "\n",
    "                self.num_timesteps += env.num_envs\n",
    "\n",
    "                # Give access to local variables\n",
    "                callback.update_locals(locals())\n",
    "                if not callback.on_step():\n",
    "                    return False\n",
    "\n",
    "                self._update_info_buffer(infos, dones)\n",
    "                n_steps += 1\n",
    "\n",
    "                if isinstance(self.action_space, spaces.Discrete):\n",
    "                    # Reshape in case of discrete action\n",
    "                    actions = actions.reshape(-1, 1)\n",
    "\n",
    "                # Handle timeout by bootstraping with value function\n",
    "                # see GitHub issue #633\n",
    "                for idx, done in enumerate(dones):\n",
    "                    if (\n",
    "                        done\n",
    "                        and infos[idx].get(\"terminal_observation\") is not None\n",
    "                        and infos[idx].get(\"TimeLimit.truncated\", False)\n",
    "                    ):\n",
    "                        terminal_obs = self.policy.obs_to_tensor(infos[idx][\"terminal_observation\"])[0]\n",
    "                        with th.no_grad():\n",
    "                            terminal_value = self.policy.predict_values(terminal_obs)[0]  # type: ignore[arg-type]\n",
    "                        rewards[idx] += self.gamma * terminal_value\n",
    "\n",
    "                rollout_buffer.add(\n",
    "                    self._last_obs,  # type: ignore[arg-type]\n",
    "                    actions,\n",
    "                    rewards,\n",
    "                    self._last_episode_starts,  # type: ignore[arg-type]\n",
    "                    values,\n",
    "                    log_probs,\n",
    "                )\n",
    "                self._last_obs = new_obs  # type: ignore[assignment]\n",
    "                self._last_episode_starts = dones\n",
    "\n",
    "            with th.no_grad():\n",
    "                # Compute value for the last timestep\n",
    "                values = self.policy.predict_values(obs_as_tensor(new_obs, self.device))  # type: ignore[arg-type]\n",
    "\n",
    "            rollout_buffer.compute_returns_and_advantage(last_values=values, dones=dones)\n",
    "\n",
    "            callback.update_locals(locals())\n",
    "\n",
    "            callback.on_rollout_end()\n",
    "\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "env1 = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# net_arch1 = [dict(vf=[32, 32], pi=[32, 32])]\n",
    "net_arch1 = [64,64]\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCombinedExtractor,\n",
    "    net_arch=net_arch1\n",
    ")\n",
    "\n",
    "model = CustomPPO(CustomActorCriticPolicy, env1, policy_kwargs=policy_kwargs, verbose=1, tensorboard_log=\"./PPO_sim_tensorboard/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./PPO_sim_tensorboard/PPO_16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a4053d43d04c33969fbde0dff3edb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 83   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 24   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092162695 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -25.5        |\n",
      "|    explained_variance   | -0.000105    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.273        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -2.9e-05     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012648478 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.4       |\n",
      "|    explained_variance   | -0.000721   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.216       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 2.17        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012517653 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.4       |\n",
      "|    explained_variance   | 0.0985      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009718765 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.4       |\n",
      "|    explained_variance   | -0.00302    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 189        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00874331 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -25.3      |\n",
      "|    explained_variance   | 0.0051     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.172      |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.00546   |\n",
      "|    std                  | 0.982      |\n",
      "|    value_loss           | 1.09       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006910639 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.2       |\n",
      "|    explained_variance   | -0.00108    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.204       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 0.828       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008839786 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.2       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.213       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 0.905       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008642776 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.2       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.713       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010424863 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.66        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010393503 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.862       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011249866 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.245       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 0.931       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 448         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014164559 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.2       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.257       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010259429 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.213       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.001       |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 527        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00969194 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -25.1      |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.346      |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | 0.000384   |\n",
      "|    std                  | 0.974      |\n",
      "|    value_loss           | 1.37       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 566         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011395498 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25         |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.375       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.00299     |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 599         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011538069 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25         |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.0092      |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 633         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013214165 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25         |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.298       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.0102      |\n",
      "|    std                  | 0.972       |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012220078 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25         |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 718         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010526914 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.307       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.0251      |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 753         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011304972 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.231       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.0235      |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 791         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014474273 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | 0.036       |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 1.16        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 829         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015956115 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | 0.0424      |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 1.23        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 871         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019359292 |\n",
      "|    clip_fraction        | 0.424       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.964       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.0579      |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 915         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036423203 |\n",
      "|    clip_fraction        | 0.529       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.312       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.0821      |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 959         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022477292 |\n",
      "|    clip_fraction        | 0.48        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | -0.115      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.209       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.0684      |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 55         |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 1003       |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03260953 |\n",
      "|    clip_fraction        | 0.606      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -25.1      |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.754      |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | 0.131      |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 1.09       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 1045      |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 11.144121 |\n",
      "|    clip_fraction        | 0.996     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.1     |\n",
      "|    explained_variance   | 0.248     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.23      |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | 0.327     |\n",
      "|    std                  | 0.977     |\n",
      "|    value_loss           | 1.22      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 1084      |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.0911927 |\n",
      "|    clip_fraction        | 0.975     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.1     |\n",
      "|    explained_variance   | -0.166    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.434     |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | 0.284     |\n",
      "|    std                  | 0.976     |\n",
      "|    value_loss           | 0.997     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 1122      |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 10.368929 |\n",
      "|    clip_fraction        | 0.996     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.1     |\n",
      "|    explained_variance   | 0.0254    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.454     |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | 0.3       |\n",
      "|    std                  | 0.977     |\n",
      "|    value_loss           | 1.1       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1161        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028658174 |\n",
      "|    clip_fraction        | 0.591       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.236       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.0998      |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 1.48        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 1199      |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 13.357855 |\n",
      "|    clip_fraction        | 0.999     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.1     |\n",
      "|    explained_variance   | -0.0103   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.687     |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | 0.278     |\n",
      "|    std                  | 0.975     |\n",
      "|    value_loss           | 2.02      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 1232      |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 12.525731 |\n",
      "|    clip_fraction        | 0.998     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.1     |\n",
      "|    explained_variance   | -0.188    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1         |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | 0.293     |\n",
      "|    std                  | 0.975     |\n",
      "|    value_loss           | 1.33      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 1266      |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 7.2572503 |\n",
      "|    clip_fraction        | 0.995     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.1     |\n",
      "|    explained_variance   | 0.12      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.547     |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | 0.28      |\n",
      "|    std                  | 0.975     |\n",
      "|    value_loss           | 1.61      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 1301      |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 5.4180202 |\n",
      "|    clip_fraction        | 0.99      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.1     |\n",
      "|    explained_variance   | 0.0743    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.874     |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | 0.383     |\n",
      "|    std                  | 0.974     |\n",
      "|    value_loss           | 1.84      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 55       |\n",
      "|    iterations           | 36       |\n",
      "|    time_elapsed         | 1338     |\n",
      "|    total_timesteps      | 73728    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 9.19696  |\n",
      "|    clip_fraction        | 0.996    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -25.1    |\n",
      "|    explained_variance   | 0.123    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.959    |\n",
      "|    n_updates            | 350      |\n",
      "|    policy_gradient_loss | 0.288    |\n",
      "|    std                  | 0.974    |\n",
      "|    value_loss           | 2.15     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 1378      |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 10.565066 |\n",
      "|    clip_fraction        | 0.997     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.1     |\n",
      "|    explained_variance   | 0.432     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.864     |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | 0.316     |\n",
      "|    std                  | 0.975     |\n",
      "|    value_loss           | 2.7       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 55       |\n",
      "|    iterations           | 38       |\n",
      "|    time_elapsed         | 1413     |\n",
      "|    total_timesteps      | 77824    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 17.08856 |\n",
      "|    clip_fraction        | 0.998    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -25.1    |\n",
      "|    explained_variance   | 0.56     |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.88     |\n",
      "|    n_updates            | 370      |\n",
      "|    policy_gradient_loss | 0.46     |\n",
      "|    std                  | 0.978    |\n",
      "|    value_loss           | 3.08     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 1449      |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.8183687 |\n",
      "|    clip_fraction        | 0.982     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.1     |\n",
      "|    explained_variance   | 0.664     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.13      |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | 0.289     |\n",
      "|    std                  | 0.979     |\n",
      "|    value_loss           | 3.21      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 55       |\n",
      "|    iterations           | 40       |\n",
      "|    time_elapsed         | 1486     |\n",
      "|    total_timesteps      | 81920    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 10.70259 |\n",
      "|    clip_fraction        | 0.999    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -25.2    |\n",
      "|    explained_variance   | 0.618    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 5.42     |\n",
      "|    n_updates            | 390      |\n",
      "|    policy_gradient_loss | 0.281    |\n",
      "|    std                  | 0.979    |\n",
      "|    value_loss           | 4.76     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 55       |\n",
      "|    iterations           | 41       |\n",
      "|    time_elapsed         | 1520     |\n",
      "|    total_timesteps      | 83968    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 6.31777  |\n",
      "|    clip_fraction        | 0.995    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -25.2    |\n",
      "|    explained_variance   | 0.452    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 1.01     |\n",
      "|    n_updates            | 400      |\n",
      "|    policy_gradient_loss | 0.277    |\n",
      "|    std                  | 0.983    |\n",
      "|    value_loss           | 3.77     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 55       |\n",
      "|    iterations           | 42       |\n",
      "|    time_elapsed         | 1553     |\n",
      "|    total_timesteps      | 86016    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 6.325103 |\n",
      "|    clip_fraction        | 0.994    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -25.2    |\n",
      "|    explained_variance   | 0.354    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 1.02     |\n",
      "|    n_updates            | 410      |\n",
      "|    policy_gradient_loss | 0.261    |\n",
      "|    std                  | 0.982    |\n",
      "|    value_loss           | 3.18     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 1585      |\n",
      "|    total_timesteps      | 88064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 10.660513 |\n",
      "|    clip_fraction        | 0.998     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.2     |\n",
      "|    explained_variance   | 0.45      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.623     |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | 0.301     |\n",
      "|    std                  | 0.982     |\n",
      "|    value_loss           | 2.98      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 44        |\n",
      "|    time_elapsed         | 1618      |\n",
      "|    total_timesteps      | 90112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 12.978606 |\n",
      "|    clip_fraction        | 0.999     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.2     |\n",
      "|    explained_variance   | 0.482     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.72      |\n",
      "|    n_updates            | 430       |\n",
      "|    policy_gradient_loss | 0.268     |\n",
      "|    std                  | 0.983     |\n",
      "|    value_loss           | 3.49      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 1656      |\n",
      "|    total_timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 4.3648043 |\n",
      "|    clip_fraction        | 0.989     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.2     |\n",
      "|    explained_variance   | 0.301     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.846     |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | 0.275     |\n",
      "|    std                  | 0.987     |\n",
      "|    value_loss           | 3.05      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 55        |\n",
      "|    iterations           | 46        |\n",
      "|    time_elapsed         | 1695      |\n",
      "|    total_timesteps      | 94208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.1321695 |\n",
      "|    clip_fraction        | 0.984     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -25.3     |\n",
      "|    explained_variance   | 0.253     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.696     |\n",
      "|    n_updates            | 450       |\n",
      "|    policy_gradient_loss | 0.28      |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 2.15      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 55       |\n",
      "|    iterations           | 47       |\n",
      "|    time_elapsed         | 1734     |\n",
      "|    total_timesteps      | 96256    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 7.190974 |\n",
      "|    clip_fraction        | 0.996    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -25.3    |\n",
      "|    explained_variance   | 0.301    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 1.79     |\n",
      "|    n_updates            | 460      |\n",
      "|    policy_gradient_loss | 0.274    |\n",
      "|    std                  | 0.99     |\n",
      "|    value_loss           | 3.21     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 55       |\n",
      "|    iterations           | 48       |\n",
      "|    time_elapsed         | 1774     |\n",
      "|    total_timesteps      | 98304    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 7.136961 |\n",
      "|    clip_fraction        | 0.995    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -25.3    |\n",
      "|    explained_variance   | 0.351    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.961    |\n",
      "|    n_updates            | 470      |\n",
      "|    policy_gradient_loss | 0.269    |\n",
      "|    std                  | 0.991    |\n",
      "|    value_loss           | 3.28     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 55       |\n",
      "|    iterations           | 49       |\n",
      "|    time_elapsed         | 1806     |\n",
      "|    total_timesteps      | 100352   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 8.899443 |\n",
      "|    clip_fraction        | 0.996    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -25.4    |\n",
      "|    explained_variance   | 0.264    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 4.44     |\n",
      "|    n_updates            | 480      |\n",
      "|    policy_gradient_loss | 0.274    |\n",
      "|    std                  | 0.994    |\n",
      "|    value_loss           | 4.26     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CustomPPO at 0x71170c0f3d30>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1e5, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('simple_ppo_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.addAtmosphere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the atmosphere from the simulation\n",
    "sim.removeAtmosphere()\n",
    "\n",
    "loop.pokeAmp = 1e-7\n",
    "\n",
    "#Compute the IM, blocking\n",
    "loop.computeIM()\n",
    "\n",
    "#Add the atmosphere back to the simulation\n",
    "sim.addAtmosphere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.plotIM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.flatten()\n",
    "time.sleep(1e-2)\n",
    "loop.setGain(0.3)\n",
    "loop.start()\n",
    "time.sleep(10)\n",
    "loop.stop()\n",
    "dm.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.push(10, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop.saveIM(\"simpleIM.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyRTC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
