{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import hardware classes\n",
    "from pyRTC.hardware.OOPAOInterface import OOPAOInterface\n",
    "from pyRTC.SlopesProcess import SlopesProcess\n",
    "from pyRTC.Pipeline import *\n",
    "from pyRTC.Loop import Loop\n",
    "from pyRTC.hardware.LoopGymInterface import LoopGymInterface\n",
    "\n",
    "import gymnasium\n",
    "from rtgym import DEFAULT_CONFIG_DICT\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shared memory in python is a bit annoying, we are required to unlink it from the garbage collector\n",
    "so that it will stick around in between runs, however sometime you can get into a situation where \n",
    "the SHM is not intialized properly. Usually you will see an error like: \n",
    "TypeError: buffer is too small for requested array\n",
    "\n",
    "To reset a SHM you can run the following code. Note: it will throw some garbage collector errors.\n",
    "\"\"\"\n",
    "# shm_names = [\"wfs\", \"wfsRaw\", \"wfc\", \"wfc2D\", \"signal\", \"signal2D\", \"psfShort\", \"psfLong\"] #list of SHMs to reset\n",
    "# clear_shms(shm_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration file\n",
    "def read_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        conf = yaml.safe_load(file)\n",
    "    return conf\n",
    "\n",
    "#Now we can read our YAML config file \n",
    "conf = read_yaml_file(\"simple_OOPAO_config.yaml\")\n",
    "\n",
    "#And separate it into sections for each of our AO loop components\n",
    "confLoop = conf[\"loop\"]\n",
    "confWFS = conf[\"wfs\"]\n",
    "confWFC = conf[\"wfc\"]\n",
    "confPSF = conf[\"psf\"]\n",
    "confSlopes = conf[\"slopes\"]\n",
    "\n",
    "print(confLoop)\n",
    "print(confWFS)\n",
    "print(confWFC)\n",
    "print(confPSF)\n",
    "print(confSlopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpleParamFile import *\n",
    "param = initializeParameterFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the OOPAO simulation interface object \n",
    "Running this cell will initialize the dm, wfs, psf, and slopes objects, \n",
    "but will not start their real time computations. This inialization includes\n",
    "the creation of the Shared Memory Objects, and the simulation inialization.\n",
    "\"\"\"\n",
    "sim = OOPAOInterface(conf=conf, param=param)\n",
    "wfs, dm, psf = sim.get_hardware()\n",
    "\n",
    "plt.imshow(wfs.wfs.cam.frame)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(dm.layout)\n",
    "plt.show()\n",
    "\n",
    "print(f\"NUM VALID ACT: {np.sum(dm.layout)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "It's important to set the full basis and number of possible modes before\n",
    "initializing the loop object. Here I define a KL basis for the system\n",
    "\"\"\"\n",
    "from OOPAO.calibration.compute_KL_modal_basis import compute_KL_basis\n",
    "\n",
    "NUM_MODES = 18\n",
    "\n",
    "M2C_KL = compute_KL_basis(sim.tel, sim.atm, sim.dm)\n",
    "dm.setM2C(M2C_KL[:,:NUM_MODES])\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "slopes = SlopesProcess(conf=conf)\n",
    "\n",
    "\"\"\" \n",
    "\"\"\"\n",
    "#Initialize our AO loop object\n",
    "loop = Loop(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Start the processes. Here the real-time computations selected in\n",
    "the config will begin.\n",
    "\"\"\"\n",
    "dm.start()\n",
    "dm.flatten()\n",
    "\n",
    "wfs.start()\n",
    "slopes.start()\n",
    "\n",
    "#Take new reference slopes while dm is flat.\n",
    "# time.sleep(1)\n",
    "# slopes.takeRefSlopes()\n",
    "\n",
    "print(sim.dm.OPD.shape)\n",
    "psf.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 30}\n",
    "\n",
    "    def __init__(self, loop, render_mode=None, buffer=0):\n",
    "        super().__init__()\n",
    "        self.loop = loop\n",
    "        self.buffer = buffer\n",
    "        self.render_mode = render_mode\n",
    "        self.default_action = np.zeros(self.loop.confWFC['numModes'], dtype=np.float32)\n",
    "        self.flat2D = self.flat2D = np.zeros((self.loop.wfc2D_width, self.loop.wfc2D_height))\n",
    "        self.active_modes = self.loop.numActiveModes\n",
    "    \n",
    "\n",
    "        self.timestep_limit = 100\n",
    "        self.current_step = 0\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        \n",
    "        # Example for using image as input (channel-first; channel-last also works):\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                \"slopes\": spaces.Box(low=-1, high=1,\n",
    "                                            shape=(self.loop.slopes_width, self.loop.slopes_height), dtype=np.float32),\n",
    "                \"command\": spaces.Box(low=-1, high=1,\n",
    "                                            shape=(self.loop.wfc2D_width, self.loop.wfc2D_height), dtype=np.float32)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.loop.confWFC[\"numModes\"], ) , dtype=np.float32)\n",
    "\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"A private method to build an observation from a state\"\"\"\n",
    "\n",
    "        self._normalized_slopes = self._slopes_obs\n",
    "        self._normalized_cmd2D = self._cmd2D_obs\n",
    "\n",
    "        if not np.all(self._cmd2D_obs == 0):\n",
    "            self._normalized_cmd2D = self._cmd2D_obs / np.linalg.norm(self._cmd2D_obs)\n",
    "\n",
    "        if not np.all(self._slopes_obs == 0):\n",
    "            self._normalized_slopes = self._slopes_obs / np.linalg.norm(self._slopes_obs)\n",
    "\n",
    "        return {\"slopes\": self._normalized_slopes, \"command\": self._normalized_cmd2D}\n",
    "    \n",
    "    \n",
    "    def _get_info(self):\n",
    "        return {\n",
    "            'TimeLimit.truncated': False\n",
    "        }\n",
    "    \n",
    "\n",
    "    def _send_control(self, control):\n",
    "\n",
    "        control[self.active_modes:] = 0\n",
    "\n",
    "        self.control = control\n",
    "        \n",
    "        self.loop.wfcShm.write(control)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "\n",
    "        #send the command to the mirror\n",
    "        self._send_control(action)\n",
    "\n",
    "        # make a blocking read of the wfc to make sure the action has been set\n",
    "        self._cmd2D_obs = self.loop.wfc2DShm.read()\n",
    "\n",
    "        # read the slopes\n",
    "        self._slopes_obs = self.loop.slopesShm.read()\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        # Compute reward\n",
    "        reward = np.exp(-np.var(self._slopes_obs), dtype=np.float32).item()\n",
    "\n",
    "        #Terminated condition -> divergent slopes\n",
    "        terminated = bool(reward < np.exp(-9))\n",
    "\n",
    "        # Info + Truncation\n",
    "        if self.current_step >= self.timestep_limit:\n",
    "            truncated = True\n",
    "            info = {'TimeLimit.truncated': True}\n",
    "        else:\n",
    "            truncated = False\n",
    "            info = {'TimeLimit.truncated': False}\n",
    "\n",
    "        \n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.current_step = 0\n",
    "\n",
    "        #Flatten the mirror\n",
    "        self._send_control(self.default_action)\n",
    "\n",
    "        # Sleep to make sure the blocking order is reset\n",
    "        time.sleep(0.01)\n",
    "\n",
    "        #Set the current command\n",
    "        self._cmd2D_obs = self.loop.wfc2DShm.read()\n",
    "\n",
    "        #Read the slopes\n",
    "        self._slopes_obs = self.loop.slopesShm.read()\n",
    "\n",
    "        #Build the observation\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        # Get info dict\n",
    "        info = self._get_info()\n",
    "\n",
    "    \n",
    "        return observation, info\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == None:\n",
    "            return\n",
    "\n",
    "    def close(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyRTC.hardware.GymEnv import CustomEnv\n",
    "\n",
    "env = CustomEnv(loop=loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "for i in range(10):\n",
    "    obs, reward, *_ = env.step(env.action_space.sample())\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "obs, *_ = env.step(env.action_space.sample())\n",
    "\n",
    "plt.imshow(obs['slopes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common import env_checker\n",
    "\n",
    "env_checker.check_env(env, warn=True, skip_render_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch as th\n",
    "from torch import nn\n",
    "\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "\n",
    "class CustomCombinedExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Dict):\n",
    "        # We do not know features-dim here before going over all the items,\n",
    "        # so put something dummy for now. PyTorch requires calling\n",
    "        # nn.Module.__init__ before adding modules\n",
    "        super().__init__(observation_space, features_dim=1)\n",
    "\n",
    "        self._numFeatures = 16\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding='same'),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Flatten())\n",
    "        \n",
    "\n",
    "        # find the output size of the CNN for each obs\n",
    "        n_flatten = {}\n",
    "\n",
    "        \n",
    "        with th.no_grad():\n",
    "            for key, subspace in observation_space.spaces.items():\n",
    "\n",
    "                n_flatten[key] = self.cnn(\n",
    "                    th.as_tensor(observation_space.sample()[key][np.newaxis,:,:]).float()\n",
    "                ).numel()\n",
    "\n",
    "        print(n_flatten)        \n",
    "\n",
    "    \n",
    "        extractors = {}\n",
    "\n",
    "        # We need to know size of the output of this extractor,\n",
    "        # so go over all the spaces and compute output feature sizes\n",
    "        for key, subspace in observation_space.spaces.items():\n",
    "            if key == \"slopes\":\n",
    "                # We will just downsample one channel of the image by 4x4 and flatten.\n",
    "                # Assume the image is single-channel (subspace.shape[0] == 0)\n",
    "                extractors[key] = nn.Sequential(self.cnn,\n",
    "                                nn.Linear(n_flatten[key], self._numFeatures),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Flatten())\n",
    "                \n",
    "            elif key == \"command\":\n",
    "                # Run through a simple MLP\n",
    "                extractors[key] = nn.Sequential(self.cnn,\n",
    "                                nn.Linear(n_flatten[key], self._numFeatures),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Flatten())\n",
    "\n",
    "        self.extractors = nn.ModuleDict(extractors)\n",
    "\n",
    "        # Update the features dim manually\n",
    "        self._features_dim = 32\n",
    "\n",
    "    def forward(self, observations) -> th.Tensor:\n",
    "        encoded_tensor_list = []\n",
    "\n",
    "        # self.extractors contain nn.Modules that do all the processing.\n",
    "        for key, extractor in self.extractors.items():\n",
    "            print(th.Tensor(observations[key][:, np.newaxis, :, :]).shape)\n",
    "            print(extractor(th.Tensor(observations[key][:, np.newaxis,:, :])).shape)\n",
    "            encoded_tensor_list.append(extractor(th.Tensor(observations[key][:, np.newaxis, :, :])).view(1,-1))\n",
    "        # Return a (B, self._features_dim) PyTorch tensor, where B is batch dimension.\n",
    "        return th.cat(encoded_tensor_list, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "env1 = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.empty((64,5,5))\n",
    "\n",
    "print(x[:,np.newaxis,:,:].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "env1.reset()\n",
    "\n",
    "obs, *_ = env1.step([env.action_space.sample()])\n",
    "\n",
    "print(obs)\n",
    "\n",
    "def merge_ordered_dicts(d1, d2):\n",
    "    merged_dict = OrderedDict()\n",
    "    for key in d1:\n",
    "        # Each key points to a list of values from both dictionaries\n",
    "        merged_dict[key] = [d1[key], d2[key]]\n",
    "    return merged_dict\n",
    "\n",
    "# Merging the dictionaries\n",
    "merged_dict = merge_ordered_dicts(obs, obs)\n",
    "\n",
    "print(CustomCombinedExtractor(env.observation_space)(merged_dict).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCombinedExtractor,\n",
    "    net_arch=[32, 32],\n",
    ")\n",
    "\n",
    "model = PPO(\"MultiInputPolicy\", env1, policy_kwargs=policy_kwargs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.addAtmosphere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the atmosphere from the simulation\n",
    "sim.removeAtmosphere()\n",
    "\n",
    "loop.pokeAmp = 1e-7\n",
    "\n",
    "#Compute the IM, blocking\n",
    "loop.computeIM()\n",
    "\n",
    "#Add the atmosphere back to the simulation\n",
    "sim.addAtmosphere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.plotIM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.flatten()\n",
    "time.sleep(1e-2)\n",
    "loop.setGain(0.3)\n",
    "loop.start()\n",
    "time.sleep(10)\n",
    "loop.stop()\n",
    "dm.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.push(10, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop.saveIM(\"simpleIM.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyRTC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
